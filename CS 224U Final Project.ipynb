{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 224U Final Project: Relation Extraction with Graph Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Authors:** Ben Barnett and Aakash Pattabi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import sys\n",
    "from pycorenlp import StanfordCoreNLP\n",
    "from collections import defaultdict\n",
    "import subprocess\n",
    "import sys\n",
    "import random\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Loading TACRED data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_path = \"tacred/data/json/train.json\"\n",
    "eval_path = \"tacred/data/json/dev.json\"\n",
    "test_path = \"tacred/data/json/test.json\"\n",
    "\n",
    "with open(train_path, \"rb\") as f:\n",
    "    train_data = json.load(f)\n",
    "    \n",
    "with open(eval_path, \"rb\") as f:\n",
    "    eval_data = json.load(f)\n",
    "    \n",
    "with open(test_path, \"rb\") as f:\n",
    "    test_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68124 training samples\n",
      "22631 dev samples\n",
      "15509 test samples\n"
     ]
    }
   ],
   "source": [
    "print(\"{} training samples\".format(len(train_data)))\n",
    "print(\"{} dev samples\".format(len(eval_data)))\n",
    "print(\"{} test samples\".format(len(test_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Defining a sentence-level feature extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class GraphFeatureExtractor(object):\n",
    "    def __init__(self, server, parse_level = \"basic\", \n",
    "                 embedding_path = None):\n",
    "        self.server = server\n",
    "        self.set_parse_level(parse_level)\n",
    "        \n",
    "        # Initialize word embeddings\n",
    "        if embedding_path:\n",
    "            self.embedding_path = embedding_path\n",
    "            self._load_embeddings()\n",
    "        else:\n",
    "            self.embedding_path = None\n",
    "            \n",
    "        self._reset_class_distribution()\n",
    "        self._reset_class_labels()\n",
    "    \n",
    "    def _reset_class_labels(self):\n",
    "        self.class_labels = {}\n",
    "    \n",
    "    def _reset_class_distribution(self):\n",
    "        self.class_distribution = defaultdict(int)\n",
    "        self.sentences_seen = 0\n",
    "        \n",
    "    def _load_embeddings(self):\n",
    "        self.embeddings = {}\n",
    "        with open(self.embedding_path, \"r\", encoding = \"utf-8\") as f:\n",
    "            for line in f:\n",
    "                tokens = line.split()\n",
    "                self.embeddings[tokens[0]] = [float(i) for i in tokens[1:]]\n",
    "    \n",
    "    def get_class_labels(self):\n",
    "        return self.class_labels\n",
    "    \n",
    "    def set_parse_level(self, parse_level):\n",
    "        assert parse_level in [\"basic\", \"enhanced\", \"extra_enhanced\"]\n",
    "        d = {\n",
    "            \"basic\" : \"basicDependencies\",\n",
    "            \"enhanced\" : \"enhancedDependencies\", \n",
    "            \"extra_enhanced\" : \"enhancedPlusPlusDependencies\"\n",
    "        }\n",
    "        self.parse_level = d[parse_level]\n",
    "    \n",
    "    def _extract_graph(self, sentence):\n",
    "        Y = sentence[\"relation\"]\n",
    "        self.class_distribution[Y] += 1\n",
    "        self.sentences_seen += 1\n",
    "        if Y not in self.class_labels:\n",
    "            self.class_labels[Y] = len(self.class_labels)\n",
    "        \n",
    "        # Extract tokens, subsentence (b/w subj->obj tokens)\n",
    "        tokens = sentence[\"token\"]\n",
    "        first = min(sentence[\"subj_start\"], sentence[\"obj_start\"])\n",
    "        second = max(sentence[\"subj_end\"], sentence[\"obj_end\"])\n",
    "        middle = tokens[first:second+1]\n",
    "\n",
    "        # Concatenate full sentence and sentence middle (b/w subj->obj tokens)\n",
    "        full_sentence = \" \".join(tokens)\n",
    "        full_middle = \" \".join(middle)\n",
    "        \n",
    "        # Parse with Stanford parser\n",
    "        full_sentence_out = server.annotate(full_sentence, properties = {\n",
    "            \"annotators\" : \"parse\", \n",
    "            \"outputFormat\" : \"json\"\n",
    "        })\n",
    "        middle_out = server.annotate(full_middle, properties = {\n",
    "            \"annotators\" : \"parse\", \n",
    "            \"outputFormat\" : \"json\"\n",
    "        })\n",
    "        \n",
    "        # Extract graph edgelist\n",
    "        X_full, full_tokens = self._parse_to_graph(full_sentence_out)\n",
    "        X_middle, middle_tokens = self._parse_to_graph(middle_out)\n",
    "        \n",
    "        # Add word-level GloVe features to graph inputs\n",
    "        if self.embedding_path:\n",
    "            X_full[\"features\"] = self._get_embedding_features(full_tokens)\n",
    "            for k in set().union(*X_full[\"edges\"]): # Error-checking to make sure G2V completes\n",
    "                assert k in X_full[\"features\"]\n",
    "            \n",
    "            X_middle[\"features\"] = self._get_embedding_features(middle_tokens)\n",
    "            for k in set().union(*X_middle[\"edges\"]): # Error-checking to make sure G2V completes\n",
    "                assert k in X_middle[\"features\"]\n",
    "        \n",
    "        return {\"full\" : X_full, \"middle\" : X_middle, \"Y\" : Y}\n",
    "        \n",
    "    def _parse_to_graph(self, parse):                        \n",
    "        dep_list = parse[\"sentences\"][0][self.parse_level]\n",
    "        dep_graph = defaultdict(lambda : [])\n",
    "        for d in dep_list:\n",
    "                dep_graph[d[\"governor\"]].append(d[\"dependent\"])\n",
    "        \n",
    "        parser_tokens = [tok[\"word\"] for tok in parse[\"sentences\"][0][\"tokens\"]]\n",
    "        return self._convert_to_edgelist(dep_graph), parser_tokens\n",
    "    \n",
    "    def _convert_to_edgelist(self, dep_graph):\n",
    "        el = {\n",
    "            \"edges\" : [[k, vi] for k, v in dep_graph.items() for vi in v] \n",
    "        }        \n",
    "        return el\n",
    "    \n",
    "    def _get_embedding_features(self, sent, embedding_dim = 50):\n",
    "        feats = {}\n",
    "        for i, token in enumerate(sent):\n",
    "            features = self.embeddings.get(token, None)\n",
    "            if not features:\n",
    "                features = [np.random.rand() for j in range(embedding_dim)]\n",
    "            feats[i+1] = features\n",
    "            \n",
    "        # By default, we assign the [ROOT] token in the parse tree an embedding vector\n",
    "        # of all zeroes... mostly because I'm not strictly sure what else to do here. @Ben, thoughts?\n",
    "        feats[0] = [0]*embedding_dim\n",
    "        return feats\n",
    "    \n",
    "    def extract_batch_graphs(self, sentences):\n",
    "        n_sentences = len(sentences)\n",
    "        batch = []\n",
    "        for i, s in enumerate(sentences):\n",
    "            batch.append(self._extract_graph(s))\n",
    "            print(\"Extracted graphs for [{}/{}] sentences...\".format(i+1, n_sentences), end = \"\\r\")\n",
    "            sys.stdout.flush()\n",
    "\n",
    "        return batch\n",
    "    \n",
    "    def extract_resampled_graphs(self, features, total):\n",
    "        n_to_resample = total - len(features)\n",
    "        if n_to_resample <= 0:\n",
    "            return\n",
    "        \n",
    "        resampled_features = []\n",
    "        while n_to_resample > 0:\n",
    "            feat = random.choice(features)\n",
    "            rel = feat[\"Y\"]\n",
    "            frequency = self.class_distribution[rel]/self.sentences_seen\n",
    "            keep = (np.random.rand() > frequency)\n",
    "            if keep:\n",
    "                resampled_features.append(feat)\n",
    "                n_to_resample -= 1\n",
    "        return resampled_features\n",
    "    \n",
    "    def save_jsons(self, graphs, save_path):\n",
    "        assert save_path and save_path[-1] == \"/\"\n",
    "        for i, g in enumerate(graphs):\n",
    "            with open(save_path + str(i) + \".json\", \"w\") as f:\n",
    "                json.dump(g, f)\n",
    "    \n",
    "    def concat_with_mean_embedding(self, features, embedding_dicts):\n",
    "        n, d = features.shape\n",
    "        mean_embeddings = []\n",
    "        for i in range(n):\n",
    "            mean_embeddings.append(np.mean([v for k, v in embedding_dicts[i].items()], axis = 0))\n",
    "        return np.concatenate((features, mean_embeddings), axis = 1)\n",
    "    \n",
    "    def concat_with_sum_embedding(self, features, embedding_dicts):\n",
    "        n, d = features.shape\n",
    "        sum_embeddings = []\n",
    "        for i in range(n):\n",
    "            sum_embeddings.append(np.sum([v for k, v in embedding_dicts[i].items()], axis = 0))\n",
    "        return np.concatenate((features, sum_embeddings), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional features to implement:\n",
    "1. ~~Resampling of the original data to augment data size + reduce class imbalance that *doesn't* duplicate Graph2Vec features across repeated samples.~~\n",
    "2. ~~Creating a full TAC dataset-to-features pipeline that can be deployed on arbitrary data~~ \n",
    "3. Incorporation of e.g. parse tree label information into the features. \n",
    "4. ~~Classifiers - implement logistic regression, set up as a neural network.~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Defining a full feature-extraction pipeline that can be used on arbitrary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class FeatureExtractorPipeline(object):\n",
    "    def __init__(self, fe_args, save_paths):\n",
    "        self.fe = GraphFeatureExtractor(**fe_args)\n",
    "        self.save_paths = save_paths\n",
    "        self.class_labels = None\n",
    "    \n",
    "    def _one_hot(self, length, hot):\n",
    "        a = np.zeros(length)\n",
    "        a[hot] = 1\n",
    "        return a\n",
    "    \n",
    "    def _extract_training_graphs(self, sentences, total, train_flag):\n",
    "        feats = self.fe.extract_batch_graphs(sentences)\n",
    "        if total > len(sentences):\n",
    "            resampled_feats = self.fe.extract_resampled_graphs(feats, total)\n",
    "            feats += resampled_feats\n",
    "            assert len(feats) == total    \n",
    "        \n",
    "        self.fe.save_jsons(\n",
    "            [feat[\"full\"] for feat in feats], \n",
    "            self.save_paths[train_flag + \"_full_save_path\"]\n",
    "        )\n",
    "        self.fe.save_jsons(\n",
    "            [feat[\"middle\"] for feat in feats], \n",
    "            self.save_paths[train_flag + \"_middle_save_path\"]\n",
    "        )\n",
    "        \n",
    "        self.class_labels = self.fe.get_class_labels()\n",
    "        n_classes = len(self.class_labels)\n",
    "        Y = [self._one_hot(n_classes, self.class_labels[feat[\"Y\"]]) for feat in feats]\n",
    "        X_full_embs = [feat[\"full\"][\"features\"] for feat in feats]\n",
    "        X_middle_embs = [feat[\"middle\"][\"features\"] for feat in feats]\n",
    "        \n",
    "        return Y, X_full_embs, X_middle_embs\n",
    "    \n",
    "    def _extract_training_embeddings(self, \n",
    "                                     X_full_embs, X_middle_embs,\n",
    "                                     train_flag, \n",
    "                                     concat = \"mean\"):\n",
    "        assert concat in [\"mean\", \"sum\", \"both\"]\n",
    "        \n",
    "        success_full = subprocess.call(\n",
    "            [\"python\", \n",
    "             \"graph2vec/src/graph2vec.py\", \n",
    "             \"--input-path\", self.save_paths[train_flag + \"_full_save_path\"], \n",
    "             \"--output-path\", self.save_paths[train_flag + \"_full_g2v_path\"]]\n",
    "        )\n",
    "        assert success_full == 0\n",
    "        \n",
    "        success_middle = subprocess.call(\n",
    "            [\"python\", \n",
    "             \"graph2vec/src/graph2vec.py\", \n",
    "             \"--input-path\", self.save_paths[train_flag + \"_middle_save_path\"], \n",
    "             \"--output-path\", self.save_paths[train_flag + \"_middle_g2v_path\"]]\n",
    "        )\n",
    "        assert success_middle == 0\n",
    "        \n",
    "        X_full = pd.read_csv(\n",
    "            self.save_paths[train_flag + \"_full_g2v_path\"], sep = \",\").drop(labels = [\"type\"], axis = 1)\n",
    "        X_full = np.array(X_full)\n",
    "        \n",
    "        X_middle = pd.read_csv(\n",
    "            self.save_paths[train_flag + \"_middle_g2v_path\"], sep = \",\").drop(labels = [\"type\"], axis = 1)\n",
    "        X_middle = np.array(X_middle)\n",
    "        \n",
    "        if concat == \"mean\" or concat == \"both\":\n",
    "            X_full = self.fe.concat_with_mean_embedding(X_full, X_full_embs)\n",
    "            X_middle = self.fe.concat_with_mean_embedding(X_middle, X_middle_embs)\n",
    "        elif concat == \"sum\" or concat == \"both\":\n",
    "            X_full = self.fe.concat_with_sum_embedding(X_full, X_full_embs)\n",
    "            X_middle = self.fe.concat_with_sum_embedding(X_middle, X_middle_embs)\n",
    "        \n",
    "        return X_full, X_middle\n",
    "    \n",
    "    def get_class_labels(self):\n",
    "        return self.class_labels\n",
    "    \n",
    "    def extract_features(self, sentences, total = 0, \n",
    "                         train_flag = \"train\", concat = \"mean\"):\n",
    "        assert train_flag in [\"train\", \"test\", \"eval\"]\n",
    "        \n",
    "        print(\"Building graphs from sentence dependency trees...\")\n",
    "        Y, X_full_embs, X_middle_embs = self._extract_training_graphs(sentences, total, train_flag)\n",
    "        np.save(self.save_paths[\"responses\"] + train_flag, Y)\n",
    "        print(\"Resampled sentence graphs up to {} total examples in the data...\".format(len(Y)), end = \"\\r\")\n",
    "            \n",
    "        print(\"Extracting Graph2Vec embeddings and annotationg w/ GloVe vecs...\")\n",
    "        X_full, X_middle = self._extract_training_embeddings(X_full_embs, X_middle_embs, train_flag, concat)\n",
    "        X = np.concatenate((X_full, X_middle), axis = 1)\n",
    "        np.save(self.save_paths[\"features\"] + train_flag, X)\n",
    "        print(\"Done!\")\n",
    "        return Y, X_full, X_middle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Originally 50 samples in training data...\n",
      "Building graphs from sentence dependency trees...\n",
      "Extracting Graph2Vec embeddings and annotationg w/ GloVe vecs....\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "sanity_check = train_data[:50]\n",
    "server = StanfordCoreNLP('http://localhost:9000')\n",
    "embedding_path = \"./glove/glove.6B.50d.txt\"\n",
    "\n",
    "fe_args = {\n",
    "    \"server\" : server, \n",
    "    \"embedding_path\" : embedding_path\n",
    "}\n",
    "\n",
    "save_paths = {\n",
    "    \"train_full_save_path\" : \"train_features_full/\", \n",
    "    \"train_middle_save_path\" : \"train_features_middle/\",\n",
    "    \"test_full_save_path\" : \"test_features_full/\",\n",
    "    \"test_middle_save_path\" : \"test_features_middle/\",\n",
    "    \"train_full_g2v_path\" : \"train_features_full_g2v/features.csv\",\n",
    "    \"train_middle_g2v_path\" : \"train_features_middle_g2v/features.csv\",\n",
    "    \"test_full_g2v_path\" : \"test_features_full_g2v/features.csv\", \n",
    "    \"test_middle_g2v_path\" : \"test_features_middle_g2v/features.csv\",\n",
    "    \"responses\" : \"all_features/responses\",\n",
    "    \"features\" : \"all_features/features\"\n",
    "}\n",
    "\n",
    "n_samples = len(sanity_check)\n",
    "print(\"Originally {} samples in training data...\".format(n_samples))\n",
    "fep = FeatureExtractorPipeline(fe_args, save_paths)\n",
    "Y, X_full, X_middle = fep.extract_features(sanity_check, total = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's just verify really quickly that:\n",
    "1. The one-hot encoding of the labels is correct. \n",
    "2. Resampling _did_ fix any class-imbalance issues (if there were any)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Christine Egerszegi-Obrist -LRB- l -RRB- and Haddad-Adel\n",
      "Label: no_relation\n",
      "FEP label: no_relation\n",
      "# classes: 10\n",
      "{0: 'org:founded_by', 1: 'no_relation', 2: 'per:employee_of', 3: 'org:alternate_names', 4: 'per:cities_of_residence', 5: 'per:children', 6: 'per:title', 7: 'per:siblings', 8: 'per:religion', 9: 'per:age'}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 10)\n",
      "(100, 178)\n",
      "(100, 178)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Verifying that the labels are correct\n",
    "idx = random.choice(range(len(sanity_check)))\n",
    "ex = \" \".join(sanity_check[idx][\"token\"])\n",
    "label = sanity_check[idx][\"relation\"]\n",
    "print(\"Sentence: {}\\nLabel: {}\".format(ex, label))\n",
    "\n",
    "class_labels = { v : k for k, v in fep.get_class_labels().items()}\n",
    "fep_label = class_labels[np.argmax(Y[idx]).astype(int)]\n",
    "print(\"FEP label: {}\".format(fep_label))\n",
    "assert fep_label == label\n",
    "\n",
    "print(\"# classes: {}\".format(len(class_labels)))\n",
    "print(class_labels)\n",
    "# Verifying class-imbalance issues\n",
    "labels = np.argmax(Y, axis = 1)\n",
    "keys, counts = np.unique(labels, return_counts = True)\n",
    "plt.bar(keys, counts)\n",
    "plt.title(\"Class distribution in resampled data\")\n",
    "plt.xticks(keys, [class_labels[k] for k in keys], rotation = 270)\n",
    "plt.show()\n",
    "\n",
    "# Verifying that all the shapes work out...\n",
    "print(np.array(Y).shape)\n",
    "print(X_full.shape)\n",
    "print(X_middle.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Defining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import Dataset\n",
    "\n",
    "class FullyConnectedNN(nn.Module):\n",
    "    def __init__(self, architecture, input_size, output_size):\n",
    "        super().__init__()\n",
    "        architecture = [input_size] + architecture\n",
    "        self.layers = nn.ModuleList()\n",
    "        for i, neurons in enumerate(architecture[:-1]):\n",
    "            self.layers.append(nn.Linear(architecture[i], architecture[i+1]))\n",
    "        self.output_layer = nn.Linear(architecture[-1], output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            x = F.relu(layer(x))\n",
    "        return self.output_layer(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's sanity-check just to make sure the network's forward pass is functional..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0621, -0.1771]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "net = FullyConnectedNN([5, 5, 5], 10, 2)\n",
    "x = torch.rand(10).view(1, -1)\n",
    "y = net(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we write the training loop..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "class RelExtDataset(Dataset):\n",
    "    def __init__(self, X_path, Y_path, device):\n",
    "        self.X = torch.from_numpy(np.load(X_path)).float().to(device)\n",
    "        self.Y = torch.from_numpy(np.load(Y_path)).float().to(device)\n",
    "        assert len(self.X) == len(self.Y)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.Y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.Y)\n",
    "    \n",
    "class Trainer(object):\n",
    "    def __init__(self, model, optimizer, hyperparams, device):\n",
    "        self.device = device\n",
    "        self.model = model.to(self.device)\n",
    "        self.hyperparams = hyperparams\n",
    "        self.lossfn = self.hyperparams[\"loss_function\"]\n",
    "        self.optimizer = optimizer(self.model.parameters(), lr = self.hyperparams[\"lr\"])\n",
    "        self.dataset = None\n",
    "        self.epochs_trained = 0\n",
    "    \n",
    "    def load_data(self, X_path, Y_path):\n",
    "        dataset = RelExtDataset(X_path, Y_path, self.device)\n",
    "        self.dataset = DataLoader(dataset, batch_size = self.hyperparams[\"batch_size\"], num_workers = 0)\n",
    "        \n",
    "    def train(self, n_epochs, log_path, checkpoint_path, print_every = 10):\n",
    "        assert self.dataset\n",
    "        \n",
    "        if log_path:\n",
    "            writer = SummaryWriter(log_path)\n",
    "            \n",
    "        n_batches = 0\n",
    "        for epoch in range(n_epochs):\n",
    "            for batch_i, (X, Y) in enumerate(self.dataset):\n",
    "                self.optimizer.zero_grad()\n",
    "                Yhat = self.model(X)\n",
    "                loss = self.lossfn(Yhat, Y)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                \n",
    "                n_batches += 1\n",
    "                \n",
    "                if log_path:\n",
    "                    writer.add_scalar(\"loss\", loss, n_batches)\n",
    "                \n",
    "                if (n_batches % print_every == 0):\n",
    "                    loss_p = loss.detach().numpy()\n",
    "                    print(\"Epoch {0}, batch {1}: training loss = {0:.2f}\".format(epoch, n_batches, loss_p), end = \"\\r\")\n",
    "                    sys.stdout.flush()\n",
    "                \n",
    "            self.epochs_trained += 1\n",
    "            \n",
    "            if checkpoint_path:\n",
    "                with open(checkpoint_path + \"checkpoint_epoch_{}.pkl\".format(epoch), \"wb\") as f:\n",
    "                    pickle.dump(self.get_pickleable_model(), f)\n",
    "    \n",
    "    def get_model(self):\n",
    "        return self.model\n",
    "    \n",
    "    def get_pickleable_model(self):\n",
    "        pkl = {\n",
    "            \"hyperparams\" : self.hyperparams, \n",
    "            \"epochs_trained\" : self.epochs_trained, \n",
    "            \"model_params\" : self.model.state_dict(), \n",
    "            \"optimizer_params\" : self.optimizer.state_dict()\n",
    "        }\n",
    "        return pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Training the model (!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 356\n",
    "output_size = 12\n",
    "architecture = [128, 64, 64, 64, 32]\n",
    "model = FullyConnectedNN(architecture, input_size, output_size)\n",
    "optimizer = torch.optim.Adam\n",
    "hyperparams = {\n",
    "    \"lr\" : 1e-4, \n",
    "    \"batch_size\" : 16, \n",
    "    \"loss_function\" : torch.nn.BCEWithLogitsLoss()\n",
    "}\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "trainer = Trainer(model, optimizer, hyperparams, device)\n",
    "\n",
    "X_path = save_paths[\"features\"] + \".npy\"\n",
    "Y_path = save_paths[\"responses\"] + \".npy\"\n",
    "trainer.load_data(X_path, Y_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, batch 60: training loss = 0.00000\r"
     ]
    }
   ],
   "source": [
    "log_path = None\n",
    "checkpoint_path = None\n",
    "n_epochs = 1\n",
    "trainer.train(n_epochs, log_path, checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can evaluate the model. To do that, we first need to extract the features and responses for the test dataset, which we can do using the same FEP... \n",
    "\n",
    "We then evaluate by printing a classification report (focusing on macro-averaged F1 score) as well as a confusion matrix to visualize over which relations the graph features perform particularly poorly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 1 9 0 8 0 4 2 7 1 8 4 6 2 6 8 3 3 8 9]\n",
      "[6 8 3 6 7 9 6 5 6 3 1 0 8 8 5 5 3 2 6 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00         2\n",
      "           3       0.33      0.33      0.33         3\n",
      "           4       0.00      0.00      0.00         2\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.00      0.00      0.00         1\n",
      "           8       0.00      0.00      0.00         4\n",
      "           9       0.00      0.00      0.00         2\n",
      "\n",
      "   micro avg       0.05      0.05      0.05        20\n",
      "   macro avg       0.03      0.03      0.03        20\n",
      "weighted avg       0.05      0.05      0.05        20\n",
      "\n",
      "[[0 0 0 0 0 0 1 0 0 1]\n",
      " [0 0 0 1 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 1 0 0 1 0]\n",
      " [0 0 1 1 0 0 1 0 0 0]\n",
      " [1 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 1 0]\n",
      " [0 0 0 0 0 0 1 0 0 0]\n",
      " [0 1 0 0 0 1 1 1 0 0]\n",
      " [1 0 0 1 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics as m\n",
    "\n",
    "model = trainer.get_model()\n",
    "model.eval()\n",
    "\n",
    "Y, X_full, X_middle = fep.extract_features(test_data, total = 0, train_flag = \"train\")\n",
    "X_test = torch.from_numpy(np.concat((X_full, X_middle), axis = 1)).to(device)\n",
    "Yhat_test = model(X_test).numpy()\n",
    "\n",
    "gt_labels = np.argmax(Y, axis = 1)\n",
    "pred_labels = np.argmax(Yhat_test, axis = 1)\n",
    "\n",
    "class_report = m.classification_report(gt_labels, pred_labels)\n",
    "confusion = m.confusion_matrix(gt_labels, pred_labels)\n",
    "\n",
    "print(class_report)\n",
    "print(confusion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
