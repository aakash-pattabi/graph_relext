{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 224U Final Project: Relation Extraction with Graph Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Authors:** Ben Barnett and Aakash Pattabi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import sys\n",
    "from pycorenlp import StanfordCoreNLP\n",
    "from collections import defaultdict\n",
    "import subprocess\n",
    "import sys\n",
    "import random\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Loading TACRED data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_path = \"tacred/data/json/train.json\"\n",
    "eval_path = \"tacred/data/json/dev.json\"\n",
    "test_path = \"tacred/data/json/test.json\"\n",
    "\n",
    "with open(train_path, \"rb\") as f:\n",
    "    train_data = json.load(f)\n",
    "    \n",
    "with open(eval_path, \"rb\") as f:\n",
    "    eval_data = json.load(f)\n",
    "    \n",
    "with open(test_path, \"rb\") as f:\n",
    "    test_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68124 training samples\n",
      "15509 test samples\n"
     ]
    }
   ],
   "source": [
    "print(\"{} training samples\".format(len(train_data)))\n",
    "print(\"{} test samples\".format(len(test_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Defining a sentence-level feature extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class GraphFeatureExtractor(object):\n",
    "    def __init__(self, server, parse_level = \"basic\", \n",
    "                 embedding_path = None):\n",
    "        self.server = server\n",
    "        self.set_parse_level(parse_level)\n",
    "        \n",
    "        # Initialize word embeddings\n",
    "        if embedding_path:\n",
    "            self.embedding_path = embedding_path\n",
    "            self._load_embeddings()\n",
    "        else:\n",
    "            self.embedding_path = None\n",
    "            \n",
    "        self._reset_class_distribution()\n",
    "        self._reset_class_labels()\n",
    "    \n",
    "    def _reset_class_labels(self):\n",
    "        self.class_labels = {}\n",
    "    \n",
    "    def _reset_class_distribution(self):\n",
    "        self.class_distribution = defaultdict(int)\n",
    "        self.sentences_seen = 0\n",
    "        \n",
    "    def _load_embeddings(self):\n",
    "        self.embeddings = {}\n",
    "        with open(self.embedding_path, \"r\") as f:\n",
    "            for line in f:\n",
    "                tokens = line.split()\n",
    "                self.embeddings[tokens[0]] = [float(i) for i in tokens[1:]]\n",
    "    \n",
    "    def get_class_labels(self):\n",
    "        return self.class_labels\n",
    "    \n",
    "    def set_parse_level(self, parse_level):\n",
    "        assert parse_level in [\"basic\", \"enhanced\", \"extra_enhanced\"]\n",
    "        d = {\n",
    "            \"basic\" : \"basicDependencies\",\n",
    "            \"enhanced\" : \"enhancedDependencies\", \n",
    "            \"extra_enhanced\" : \"enhancedPlusPlusDependencies\"\n",
    "        }\n",
    "        self.parse_level = d[parse_level]\n",
    "    \n",
    "    def _extract_graph(self, sentence):\n",
    "        Y = sentence[\"relation\"]\n",
    "        self.class_distribution[Y] += 1\n",
    "        self.sentences_seen += 1\n",
    "        if Y not in self.class_labels:\n",
    "            self.class_labels[Y] = len(self.class_labels)\n",
    "        \n",
    "        # Extract tokens, subsentence (b/w subj->obj tokens)\n",
    "        tokens = sentence[\"token\"]\n",
    "        first = min(sentence[\"subj_end\"], sentence[\"obj_end\"])\n",
    "        second = max(sentence[\"subj_start\"], sentence[\"obj_start\"])\n",
    "        middle = tokens[first:second+1]\n",
    "\n",
    "        # Concatenate full sentence and sentence middle (b/w subj->obj tokens)\n",
    "        full_sentence = \" \".join(tokens)\n",
    "        full_middle = \" \".join(middle)\n",
    "        \n",
    "        # Parse with Stanford parser\n",
    "        full_sentence_out = server.annotate(full_sentence, properties = {\n",
    "            \"annotators\" : \"parse\", \n",
    "            \"outputFormat\" : \"json\"\n",
    "        })\n",
    "        middle_out = server.annotate(full_middle, properties = {\n",
    "            \"annotators\" : \"parse\", \n",
    "            \"outputFormat\" : \"json\"\n",
    "        })\n",
    "        \n",
    "        # Extract graph edgelist\n",
    "        X_full = self._parse_to_graph(full_sentence_out)\n",
    "        X_middle = self._parse_to_graph(middle_out)\n",
    "        \n",
    "        # Add word-level GloVe features to graph inputs\n",
    "        if self.embedding_path:\n",
    "            X_full[\"features\"] = self._get_embedding_features(tokens)\n",
    "            X_middle[\"features\"] = self._get_embedding_features(middle)\n",
    "        \n",
    "        return {\"full\" : X_full, \"middle\" : X_middle, \"Y\" : Y}\n",
    "        \n",
    "    def _parse_to_graph(self, parse):\n",
    "        dep_list = parse[\"sentences\"][0][self.parse_level]\n",
    "        dep_graph = defaultdict(lambda : [])\n",
    "        for d in dep_list:\n",
    "            dep_graph[d[\"governor\"]].append(d[\"dependent\"])\n",
    "        return self._convert_to_edgelist(dep_graph)\n",
    "    \n",
    "    def _convert_to_edgelist(self, dep_graph):\n",
    "        el = {\n",
    "            \"edges\" : [[k, vi] for k, v in dep_graph.items() for vi in v] \n",
    "        }        \n",
    "        return el\n",
    "    \n",
    "    def _get_embedding_features(self, sent, embedding_dim = 50):\n",
    "        feats = {}\n",
    "        for i, token in enumerate(sent):\n",
    "            features = self.embeddings.get(token, None)\n",
    "            if not features:\n",
    "                features = [np.random.rand() for j in range(embedding_dim)]\n",
    "            feats[i+1] = features\n",
    "            \n",
    "        # By default, we assign the [ROOT] token in the parse tree an embedding vector\n",
    "        # of all zeroes... mostly because I'm not strictly sure what else to do here. @Ben, thoughts?\n",
    "        feats[0] = [0]*embedding_dim\n",
    "        return feats\n",
    "    \n",
    "    def extract_batch_graphs(self, sentences):\n",
    "        n_sentences = len(sentences)\n",
    "        batch = []\n",
    "        for i, s in enumerate(sentences):\n",
    "            batch.append(self._extract_graph(s))\n",
    "            print(\"Extracted graphs for [{}/{}] sentences...\".format(i+1, n_sentences), end = \"\\r\")\n",
    "            sys.stdout.flush()\n",
    "\n",
    "        return batch\n",
    "    \n",
    "    def extract_resampled_graphs(self, features, total):\n",
    "        n_to_resample = total - len(features)\n",
    "        if n_to_resample <= 0:\n",
    "            return\n",
    "        \n",
    "        resampled_features = []\n",
    "        while n_to_resample > 0:\n",
    "            feat = random.choice(features)\n",
    "            rel = feat[\"Y\"]\n",
    "            frequency = self.class_distribution[rel]/self.sentences_seen\n",
    "            keep = (np.random.rand() > frequency)\n",
    "            if keep:\n",
    "                resampled_features.append(feat)\n",
    "                n_to_resample -= 1\n",
    "        return resampled_features\n",
    "    \n",
    "    def save_jsons(self, graphs, save_path):\n",
    "        assert save_path and save_path[-1] == \"/\"\n",
    "        for i, g in enumerate(graphs):\n",
    "            with open(save_path + str(i) + \".json\", \"w\") as f:\n",
    "                json.dump(g, f)\n",
    "    \n",
    "    def concat_with_mean_embedding(self, features, embedding_dicts):\n",
    "        n, d = features.shape\n",
    "        mean_embeddings = []\n",
    "        for i in range(n):\n",
    "            mean_embeddings.append(np.mean([v for k, v in embedding_dicts[i].items()], axis = 0))\n",
    "        return np.concatenate((features, mean_embeddings), axis = 1)\n",
    "    \n",
    "    def concat_with_sum_embedding(self, features, embedding_dicts):\n",
    "        n, d = features.shape\n",
    "        mean_embeddings = []\n",
    "        for i in range(n):\n",
    "            mean_embeddings.append(np.sum([v for k, v in embedding_dicts[i].items()], axis = 0))\n",
    "        return np.concatenate((features, mean_embeddings), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional features to implement:\n",
    "1. ~~Resampling of the original data to augment data size + reduce class imbalance that *doesn't* duplicate Graph2Vec features across repeated samples.~~\n",
    "2. ~~Creating a full TAC dataset-to-features pipeline that can be deployed on arbitrary data~~ \n",
    "3. Incorporation of e.g. parse tree label information into the features. \n",
    "4. ~~Classifiers - implement logistic regression, set up as a neural network. ~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Defining a full feature-extraction pipeline that can be used on arbitrary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class FeatureExtractorPipeline(object):\n",
    "    def __init__(self, fe_args, save_paths):\n",
    "        self.fe = GraphFeatureExtractor(**fe_args)\n",
    "        self.save_paths = save_paths\n",
    "        self.class_labels = None\n",
    "    \n",
    "    def _one_hot(self, length, hot):\n",
    "        a = np.zeros(length)\n",
    "        a[hot] = 1\n",
    "        return a\n",
    "    \n",
    "    def _extract_training_graphs(self, sentences, total, train_flag):\n",
    "        feats = self.fe.extract_batch_graphs(sentences)\n",
    "        if total > len(sentences):\n",
    "            resampled_feats = self.fe.extract_resampled_graphs(feats, total)\n",
    "            feats += resampled_feats\n",
    "        assert len(feats) == total    \n",
    "        \n",
    "            \n",
    "        self.fe.save_jsons(\n",
    "            [feat[\"full\"] for feat in feats], \n",
    "            self.save_paths[train_flag + \"_full_save_path\"]\n",
    "        )\n",
    "        self.fe.save_jsons(\n",
    "            [feat[\"middle\"] for feat in feats], \n",
    "            self.save_paths[train_flag + \"_middle_save_path\"]\n",
    "        )\n",
    "        \n",
    "        self.class_labels = self.fe.get_class_labels()\n",
    "        n_classes = len(self.class_labels)\n",
    "        Y = [self._one_hot(n_classes, self.class_labels[feat[\"Y\"]]) for feat in feats]\n",
    "        X_full_embs = [feat[\"full\"][\"features\"] for feat in feats]\n",
    "        X_middle_embs = [feat[\"middle\"][\"features\"] for feat in feats]\n",
    "        \n",
    "        return Y, X_full_embs, X_middle_embs\n",
    "    \n",
    "    def _extract_training_embeddings(self, \n",
    "                                     X_full_embs, X_middle_embs,\n",
    "                                     train_flag, \n",
    "                                     concat = \"mean\"):\n",
    "        assert concat in [\"mean\", \"sum\", \"both\"]\n",
    "        \n",
    "        success_full = subprocess.call(\n",
    "            [\"python\", \n",
    "             \"graph2vec/src/graph2vec.py\", \n",
    "             \"--input-path\", self.save_paths[train_flag + \"_full_save_path\"], \n",
    "             \"--output-path\", self.save_paths[train_flag + \"_full_g2v_path\"]]\n",
    "        )\n",
    "        assert success_full == 0\n",
    "        \n",
    "        success_middle = subprocess.call(\n",
    "            [\"python\", \n",
    "             \"graph2vec/src/graph2vec.py\", \n",
    "             \"--input-path\", self.save_paths[train_flag + \"_middle_save_path\"], \n",
    "             \"--output-path\", self.save_paths[train_flag + \"_middle_g2v_path\"]]\n",
    "        )\n",
    "        assert success_middle == 0\n",
    "        \n",
    "        X_full = pd.read_csv(\n",
    "            self.save_paths[train_flag + \"_full_g2v_path\"], sep = \",\").drop(labels = [\"type\"], axis = 1)\n",
    "        X_full = np.array(X_full)\n",
    "        \n",
    "        X_middle = pd.read_csv(\n",
    "            self.save_paths[train_flag + \"_middle_g2v_path\"], sep = \",\").drop(labels = [\"type\"], axis = 1)\n",
    "        X_middle = np.array(X_middle)\n",
    "        \n",
    "        if concat == \"mean\" or concat == \"both\":\n",
    "            X_full = fe.concat_with_mean_embedding(X_full, X_full_embs)\n",
    "            X_middle = fe.concat_with_mean_embedding(X_middle, X_middle_embs)\n",
    "        elif concat == \"sum\" or concat == \"both\":\n",
    "            X_full = fe.concat_with_sum_embedding(X_full, X_full_embs)\n",
    "            X_middle = fe.concat_with_sum_embedding(X_middle, X_middle_embs)\n",
    "        \n",
    "        return X_full, X_middle\n",
    "    \n",
    "    def get_class_labels(self):\n",
    "        return self.class_labels\n",
    "    \n",
    "    def extract_features(self, sentences, total = 0, train_flag = \"train\", concat = \"mean\"):\n",
    "        assert train_flag in [\"train\", \"test\"]\n",
    "        \n",
    "        print(\"Building graphs from sentence dependency trees...\")\n",
    "        Y, X_full_embs, X_middle_embs = self._extract_training_graphs(sentences, total, train_flag)\n",
    "        print(\"Extracting Graph2Vec embeddings and annotationg w/ GloVe vecs...\")\n",
    "        X_full, X_middle = self._extract_training_embeddings(X_full_embs, X_middle_embs, train_flag, concat)\n",
    "        print(\"Done!\")\n",
    "        return np.array(Y), X_full, X_middle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Originally 10 samples in training data...\n",
      "Building graphs from sentence dependency trees...\n",
      "Extracting Graph2Vec embeddings and annotationg w/ GloVe vecs...\n",
      "Done!\n",
      "Now, resampled up to 100 samples!\n"
     ]
    }
   ],
   "source": [
    "small_corpus = train_data[:10]\n",
    "\n",
    "fe_args = {\n",
    "    \"server\" : server, \n",
    "    \"embedding_path\" : embedding_path\n",
    "}\n",
    "\n",
    "save_paths = {\n",
    "    \"train_full_save_path\" : \"train_features_full/\", \n",
    "    \"train_middle_save_path\" : \"train_features_middle/\",\n",
    "    \"test_full_save_path\" : \"test_features_full/\",\n",
    "    \"test_middle_save_path\" : \"test_features_middle/\",\n",
    "    \"train_full_g2v_path\" : \"train_features_full_g2v/features.csv\",\n",
    "    \"train_middle_g2v_path\" : \"train_features_middle_g2v/features.csv\",\n",
    "    \"test_full_g2v_path\" : \"test_features_full_g2v/features.csv\", \n",
    "    \"test_middle_g2v_path\" : \"test_features_middle_g2v/features.csv\"\n",
    "}\n",
    "\n",
    "n_samples = len(small_corpus)\n",
    "print(\"Originally {} samples in training data...\".format(n_samples))\n",
    "fep = FeatureExtractorPipeline(fe_args, save_paths)\n",
    "Y, X_full, X_middle = fep.extract_features(small_corpus, total = 100)\n",
    "print(\"Now, resampled up to {} samples!\".format(len(Y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_save = \"all_features/target\"\n",
    "X_full_save = \"all_features/full_features\"\n",
    "X_middle_save = \"all_features/middle_features\"\n",
    "\n",
    "np.save(Y_save, Y)\n",
    "np.save(X_full_save, X_full)\n",
    "np.save(X_middle_save, X_middle_save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's just verify really quickly that:\n",
    "1. The one-hot encoding of the labels is correct. \n",
    "2. Resampling _did_ fix any class-imbalance issues (if there were any)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Christine Egerszegi-Obrist -LRB- l -RRB- and Haddad-Adel\n",
      "Label: no_relation\n",
      "FEP label: no_relation\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 4)\n",
      "(100, 178)\n",
      "(100, 178)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Verifying that the labels are correct\n",
    "idx = random.choice(range(len(small_corpus)))\n",
    "ex = \" \".join(small_corpus[idx][\"token\"])\n",
    "label = small_corpus[idx][\"relation\"]\n",
    "print(\"Sentence: {}\\nLabel: {}\".format(ex, label))\n",
    "\n",
    "class_labels = { v : k for k, v in fep.get_class_labels().items()}\n",
    "fep_label = class_labels[np.argmax(Y[idx]).astype(int)]\n",
    "print(\"FEP label: {}\".format(fep_label))\n",
    "\n",
    "# Verifying class-imbalance issues\n",
    "labels = np.argmax(Y, axis = 1)\n",
    "keys, counts = np.unique(labels, return_counts = True)\n",
    "plt.bar(keys, counts)\n",
    "plt.title(\"Class distribution in resampled data\")\n",
    "plt.xticks(keys, [class_labels[k] for k in keys], rotation = -45)\n",
    "plt.show()\n",
    "\n",
    "# Verifying that all the shapes work out...\n",
    "print(Y.shape)\n",
    "print(X_full.shape)\n",
    "print(X_middle.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Defining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class FullyConnectedNN(nn.Module):\n",
    "    def __init__(self, architecture, input_size, output_size):\n",
    "        super().__init__()\n",
    "        architecture = [input_size] + architecture\n",
    "        self.layers = nn.ModuleList()\n",
    "        for i, neurons in enumerate(architecture[:-1]):\n",
    "            self.layers.append(nn.Linear(architecture[i], architecture[i+1]))\n",
    "        self.output_layer = nn.Linear(architecture[-1], output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            x = F.relu(layer(x))\n",
    "        return self.output_layer(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's sanity-check just to make sure the network's forward pass is functional..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4531, 0.0169]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "net = FullyConnectedNN([5, 5, 5], 10, 2)\n",
    "x = torch.rand(10).view(1, -1)\n",
    "y = net(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we write the training loop..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(object):\n",
    "    def __init__(self, model, optimizer, hyperparams):\n",
    "        self.model = model\n",
    "        self.hyperparams = hyperparams\n",
    "        self.optimizer = optimizer(model.parameters(), hyperparams[\"lr\"])\n",
    "    \n",
    "    def train(X, Y):\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
