{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 224U Final Project: Relation Extraction with Graph Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Authors:** Ben Barnett and Aakash Pattabi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "import sys\n",
    "from pycorenlp import StanfordCoreNLP\n",
    "from collections import defaultdict\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Loading TACRED data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '61b3a65fb906688c92a1', 'relation': 'no_relation', 'token': ['Ali', 'lied', 'about', 'having', 'to', 'leave', 'for', 'her', 'job', 'to', 'see', 'if', 'Jake', 'would', 'end', 'the', 'show', 'to', 'be', 'with', 'her', '.'], 'subj_start': 20, 'subj_end': 20, 'obj_start': 12, 'obj_end': 12, 'subj_type': 'PERSON', 'obj_type': 'PERSON', 'stanford_pos': ['NNP', 'VBD', 'IN', 'VBG', 'TO', 'VB', 'IN', 'PRP$', 'NN', 'TO', 'VB', 'IN', 'NNP', 'MD', 'VB', 'DT', 'NN', 'TO', 'VB', 'IN', 'PRP', '.'], 'stanford_ner': ['PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], 'stanford_head': ['2', '0', '4', '2', '6', '4', '11', '9', '11', '11', '6', '15', '15', '15', '11', '17', '15', '21', '21', '21', '17', '2'], 'stanford_deprel': ['nsubj', 'ROOT', 'mark', 'advcl', 'mark', 'xcomp', 'mark', 'nmod:poss', 'nsubj', 'mark', 'advcl', 'mark', 'nsubj', 'aux', 'advcl', 'det', 'dobj', 'mark', 'cop', 'case', 'acl', 'punct']}\n"
     ]
    }
   ],
   "source": [
    "train_path = \"tacred-relation/dataset/tacred/train.json\"\n",
    "eval_path = \"tacred-relation/dataset/tacred/dev.json\"\n",
    "test_path = \"tacred-relation/dataset/tacred/test.json\"\n",
    "\n",
    "with open(train_path, \"rb\") as f:\n",
    "    train_data = json.load(f)\n",
    "    \n",
    "with open(eval_path, \"rb\") as f:\n",
    "    eval_data = json.load(f)\n",
    "    \n",
    "with open(test_path, \"rb\") as f:\n",
    "    test_data = json.load(f)\n",
    "\n",
    "sanity = train_data[0]\n",
    "print(sanity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Defining a sentence-level feature extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class GraphFeatureExtractor(object):\n",
    "    def __init__(self, server, parse_level = \"basic\", \n",
    "                 embedding_path = None):\n",
    "        self.server = server\n",
    "        self.set_parse_level(parse_level)\n",
    "        \n",
    "        # Initialize word embeddings\n",
    "        if embedding_path:\n",
    "            self.embedding_path = embedding_path\n",
    "            self._load_embeddings()\n",
    "        else:\n",
    "            self.embedding_path = None\n",
    "            \n",
    "        self._reset_class_distribution()\n",
    "        self._reset_class_labels()\n",
    "    \n",
    "    def _reset_class_labels(self):\n",
    "        self.class_labels = {}\n",
    "    \n",
    "    def _reset_class_distribution(self):\n",
    "        self.class_distribution = defaultdict(int)\n",
    "        self.sentences_seen = 0\n",
    "        \n",
    "    def _load_embeddings(self):\n",
    "        self.embeddings = {}\n",
    "        with open(self.embedding_path, \"r\") as f:\n",
    "            for line in f:\n",
    "                tokens = line.split()\n",
    "                self.embeddings[tokens[0]] = [float(i) for i in tokens[1:]]\n",
    "    \n",
    "    def get_class_labels(self):\n",
    "        return self.class_labels\n",
    "    \n",
    "    def set_parse_level(self, parse_level):\n",
    "        assert parse_level in [\"basic\", \"enhanced\", \"extra_enhanced\"]\n",
    "        d = {\n",
    "            \"basic\" : \"basicDependencies\",\n",
    "            \"enhanced\" : \"enhancedDependencies\", \n",
    "            \"extra_enhanced\" : \"enhancedPlusPlusDependencies\"\n",
    "        }\n",
    "        self.parse_level = d[parse_level]\n",
    "    \n",
    "    def _extract_graph(self, sentence):\n",
    "        Y = sentence[\"relation\"]\n",
    "        self.class_distribution[Y] += 1\n",
    "        self.sentences_seen += 1\n",
    "        if Y not in self.class_labels:\n",
    "            self.class_labels[Y] = len(self.class_labels)\n",
    "        \n",
    "        # Extract tokens, subsentence (b/w subj->obj tokens)\n",
    "        tokens = sentence[\"token\"]\n",
    "        first = min(sentence[\"subj_end\"], sentence[\"obj_end\"])\n",
    "        second = max(sentence[\"subj_start\"], sentence[\"obj_start\"])\n",
    "        middle = tokens[first+1:second]\n",
    "\n",
    "        # Concatenate full sentence and sentence middle (b/w subj->obj tokens)\n",
    "        full_sentence = \" \".join(tokens)\n",
    "        full_middle = \" \".join(middle)\n",
    "        \n",
    "        # Parse with Stanford parser\n",
    "        full_sentence_out = server.annotate(full_sentence, properties = {\n",
    "            \"annotators\" : \"parse\", \n",
    "            \"outputFormat\" : \"json\"\n",
    "        })\n",
    "        middle_out = server.annotate(full_middle, properties = {\n",
    "            \"annotators\" : \"parse\", \n",
    "            \"outputFormat\" : \"json\"\n",
    "        })\n",
    "        \n",
    "        # Extract graph edgelist\n",
    "        X_full = self._parse_to_graph(full_sentence_out)\n",
    "        X_middle = self._parse_to_graph(middle_out)\n",
    "        \n",
    "        # Add word-level GloVe features to graph inputs\n",
    "        if self.embedding_path:\n",
    "            X_full[\"features\"] = self._get_embedding_features(tokens)\n",
    "            X_middle[\"features\"] = self._get_embedding_features(middle)\n",
    "        \n",
    "        return {\"full\" : X_full, \"middle\" : X_middle, \"Y\" : Y}\n",
    "        \n",
    "    def _parse_to_graph(self, parse):\n",
    "        dep_list = parse[\"sentences\"][0][self.parse_level]\n",
    "        dep_graph = defaultdict(lambda : [])\n",
    "        for d in dep_list:\n",
    "            dep_graph[d[\"governor\"]].append(d[\"dependent\"])\n",
    "        return self._convert_to_edgelist(dep_graph)\n",
    "    \n",
    "    def _convert_to_edgelist(self, dep_graph):\n",
    "        el = {\n",
    "            \"edges\" : [[k, vi] for k, v in dep_graph.items() for vi in v] \n",
    "        }        \n",
    "        return el\n",
    "    \n",
    "    def _get_embedding_features(self, sent, embedding_dim = 50):\n",
    "        feats = {}\n",
    "        for i, token in enumerate(sent):\n",
    "            features = self.embeddings.get(token, None)\n",
    "            if not features:\n",
    "                features = [np.random.rand() for j in range(embedding_dim)]\n",
    "            feats[i+1] = features\n",
    "            \n",
    "        # By default, we assign the [ROOT] token in the parse tree an embedding vector\n",
    "        # of all zeroes... mostly because I'm not strictly sure what else to do here. @Ben, thoughts?\n",
    "        feats[0] = [0]*embedding_dim\n",
    "        return feats\n",
    "    \n",
    "    def extract_batch_graphs(self, sentences):\n",
    "        return [self._extract_graph(s) for s in sentences]\n",
    "    \n",
    "    def extract_resampled_graphs(self, sentences, total):\n",
    "        n_to_resample = total - len(sentences)\n",
    "        if n_to_resample <= 0:\n",
    "            return\n",
    "        \n",
    "        resampled_sentences = []\n",
    "        while n_to_resample > 0:\n",
    "            for sent in sentences:\n",
    "                rel = sent[\"relation\"]\n",
    "                frequency = self.class_distribution[rel]/self.sentences_seen\n",
    "                keep = (np.random.rand() > frequency)\n",
    "                if keep:\n",
    "                    resampled_sentences.append(sent)\n",
    "                    n_to_resample -= 1\n",
    "        return self.extract_batch_graphs(resampled_sentences)\n",
    "    \n",
    "    def save_jsons(self, graphs, save_path):\n",
    "        assert save_path and save_path[-1] == \"/\"\n",
    "        for i, g in enumerate(graphs):\n",
    "            with open(save_path + str(i) + \".json\", \"w\") as f:\n",
    "                json.dump(g, f)\n",
    "    \n",
    "    def concat_with_mean_embedding(self, features, embedding_dicts):\n",
    "        n, d = features.shape\n",
    "        mean_embeddings = []\n",
    "        for i in range(n):\n",
    "            mean_embeddings.append(np.mean([v for k, v in embedding_dicts[i].items()], axis = 0))\n",
    "        return np.concatenate((features, mean_embeddings), axis = 1)\n",
    "    \n",
    "    def concat_with_sum_embedding(self, features, embedding_dicts):\n",
    "        n, d = features.shape\n",
    "        mean_embeddings = []\n",
    "        for i in range(n):\n",
    "            mean_embeddings.append(np.sum([v for k, v in embedding_dicts[i].items()], axis = 0))\n",
    "        return np.concatenate((features, mean_embeddings), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we generate all graph features (with 50-dimensional GloVe) vectors for the TACRED training set. Each sentence-level graph (over the entire sentence and over only the \"bridge\" words between the subject and the object) is saved to a .json file which we then post-process with Graph2Vec. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "embedding_path = \"./glove/glove.6B.50d.txt\"\n",
    "server = StanfordCoreNLP(\"http://localhost:9000\")\n",
    "\n",
    "fe = GraphFeatureExtractor(server, embedding_path = embedding_path)\n",
    "feats = fe.extract_batch_graphs(train_data)\n",
    "\n",
    "full_save_path = \"./train_features_full/\"\n",
    "fe.save_jsons([feat[\"full\"] for feat in feats], save_path = full_save_path)\n",
    "\n",
    "middle_save_path = \"./train_features_middle/\"\n",
    "fe.save_jsons([feat[\"middle\"] for feat in feats], save_path = middle_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we call Graph2Vec from command-line using a subprocess to generate the sentence features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feats_path = full_save_path\n",
    "out_path = \"./train_features_full_g2v/train_features_full.csv\"\n",
    "\n",
    "success = subprocess.call(\n",
    "    [\"python\", \n",
    "     \"graph2vec/src/graph2vec.py\", \n",
    "     \"--input-path\", feats_path, \n",
    "     \"--output-path\", out_path]\n",
    ")\n",
    "assert success == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can load the newly extracted features from the .csv file and use them in an arbitrary classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 228)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "X = pd.read_csv(out_path, sep = \",\").drop(labels = [\"type\"], axis = 1)\n",
    "X = np.array(X)\n",
    "X = fe.concat_with_mean_embedding(X, [feat[\"full\"][\"features\"] for feat in feats])\n",
    "X = fe.concat_with_sum_embedding(X, [feat[\"full\"][\"features\"] for feat in feats])\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional features to implement:\n",
    "1. ~~Resampling of the original data to augment data size + reduce class imbalance that *doesn't* duplicate Graph2Vec features across repeated samples.~~\n",
    "2. Creating a full TAC dataset-to-features pipeline that can be deployed on arbitrary data \n",
    "3. Incorporation of e.g. parse tree label information into the features. \n",
    "4. Classifiers - implement logistic regression, set up as a neural network. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Defining a full feature-extraction pipeline that can be used on arbitrary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class FeatureExtractorPipeline(object):\n",
    "    def __init__(self, fe_args, save_paths):\n",
    "        self.fe = GraphFeatureExtractor(**fe_args)\n",
    "        self.save_paths = save_paths\n",
    "        self.class_labels = None\n",
    "    \n",
    "    def _one_hot(self, length, hot):\n",
    "        a = np.zeros(length)\n",
    "        a[hot] = 1\n",
    "        return a\n",
    "    \n",
    "    def _extract_training_graphs(self, sentences, total, train_flag):\n",
    "        feats = self.fe.extract_batch_graphs(sentences)\n",
    "        if total > len(sentences):\n",
    "            resampled_feats = self.fe.extract_resampled_graphs(sentences, total)\n",
    "            feats += resampled_feats\n",
    "        assert len(feats) == total    \n",
    "        \n",
    "            \n",
    "        self.fe.save_jsons(\n",
    "            [feat[\"full\"] for feat in feats], \n",
    "            self.save_paths[train_flag + \"_full_save_path\"]\n",
    "        )\n",
    "        self.fe.save_jsons(\n",
    "            [feat[\"middle\"] for feat in feats], \n",
    "            self.save_paths[train_flag + \"_middle_save_path\"]\n",
    "        )\n",
    "        \n",
    "        self.class_labels = self.fe.get_class_labels()\n",
    "        n_classes = len(self.class_labels)\n",
    "        Y = [self._one_hot(n_classes, self.class_labels[feat[\"Y\"]]) for feat in feats]\n",
    "        X_full_embs = [feat[\"full\"][\"features\"] for feat in feats]\n",
    "        X_middle_embs = [feat[\"middle\"][\"features\"] for feat in feats]\n",
    "        \n",
    "        return Y, X_full_embs, X_middle_embs\n",
    "    \n",
    "    def _extract_training_embeddings(self, \n",
    "                                     X_full_embs, X_middle_embs,\n",
    "                                     train_flag, \n",
    "                                     concat = \"mean\"):\n",
    "        assert concat in [\"mean\", \"sum\", \"both\"]\n",
    "        \n",
    "        success_full = subprocess.call(\n",
    "            [\"python\", \n",
    "             \"graph2vec/src/graph2vec.py\", \n",
    "             \"--input-path\", self.save_paths[train_flag + \"_full_save_path\"], \n",
    "             \"--output-path\", self.save_paths[train_flag + \"_full_g2v_path\"]]\n",
    "        )\n",
    "        assert success_full == 0\n",
    "        \n",
    "        success_middle = subprocess.call(\n",
    "            [\"python\", \n",
    "             \"graph2vec/src/graph2vec.py\", \n",
    "             \"--input-path\", self.save_paths[train_flag + \"_middle_save_path\"], \n",
    "             \"--output-path\", self.save_paths[train_flag + \"_middle_g2v_path\"]]\n",
    "        )\n",
    "        assert success_middle == 0\n",
    "        \n",
    "        X_full = pd.read_csv(\n",
    "            self.save_paths[train_flag + \"_full_g2v_path\"], sep = \",\").drop(labels = [\"type\"], axis = 1)\n",
    "        X_full = np.array(X_full)\n",
    "        \n",
    "        X_middle = pd.read_csv(\n",
    "            self.save_paths[train_flag + \"_middle_g2v_path\"], sep = \",\").drop(labels = [\"type\"], axis = 1)\n",
    "        X_middle = np.array(X_middle)\n",
    "        \n",
    "        if concat == \"mean\" or concat == \"both\":\n",
    "            X_full = fe.concat_with_mean_embedding(X_full, X_full_embs)\n",
    "            X_middle = fe.concat_with_mean_embedding(X_middle, X_middle_embs)\n",
    "        elif concat == \"sum\" or concat == \"both\":\n",
    "            X_full = fe.concat_with_sum_embedding(X_full, X_full_embs)\n",
    "            X_middle = fe.concat_with_sum_embedding(X_middle, X_middle_embs)\n",
    "        \n",
    "        return X_full, X_middle\n",
    "    \n",
    "    def get_class_labels(self):\n",
    "        return self.class_labels\n",
    "    \n",
    "    def extract_features(self, sentences, total = 0, train_flag = \"train\"):\n",
    "        assert train_flag in [\"train\", \"test\"]\n",
    "        \n",
    "        print(\"Building graphs from sentence dependency trees...\")\n",
    "        Y, X_full_embs, X_middle_embs = self._extract_training_graphs(sentences, total, train_flag)\n",
    "        print(\"Extracting Graph2Vec embeddings and annotationg w/ GloVe vecs...\")\n",
    "        X_full, X_middle = self._extract_training_embeddings(X_full_embs, X_middle_embs, train_flag)\n",
    "        print(\"Done!\")\n",
    "        return np.array(Y), X_full, X_middle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Originally 20 samples in training data...\n",
      "Building graphs from sentence dependency trees...\n",
      "Extracting Graph2Vec embeddings and annotationg w/ GloVe vecs...\n",
      "Done!\n",
      "Now, resampled up to 100 samples!\n"
     ]
    }
   ],
   "source": [
    "fe_args = {\n",
    "    \"server\" : server, \n",
    "    \"embedding_path\" : embedding_path\n",
    "}\n",
    "\n",
    "save_paths = {\n",
    "    \"train_full_save_path\" : \"train_features_full/\", \n",
    "    \"train_middle_save_path\" : \"train_features_middle/\",\n",
    "    \"test_full_save_path\" : None, \n",
    "    \"test_middle_save_path\" : None,\n",
    "    \"train_full_g2v_path\" : \"train_features_full_g2v/features.csv\",\n",
    "    \"train_middle_g2v_path\" : \"train_features_middle_g2v/features.csv\",\n",
    "    \"test_full_g2v_path\" : None, \n",
    "    \"test_middle_g2v_path\" : None\n",
    "}\n",
    "\n",
    "n_samples = len(train_data)\n",
    "print(\"Originally {} samples in training data...\".format(n_samples))\n",
    "fep = FeatureExtractorPipeline(fe_args, save_paths)\n",
    "Y, X_full, X_middle = fep.extract_features(train_data, total = 100)\n",
    "print(\"Now, resampled up to {} samples!\".format(len(Y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's just verify really quickly that:\n",
    "1. The one-hot encoding of the labels is correct. \n",
    "2. Resampling _did_ fix any class-imbalance issues (if there were any)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Abrams started out as a legal analyst on TV and he was doing some behind the scenes management at MSNBC for awhile , so I do n't think he 's that interested in being a `` star '' in the news world like some others .\n",
      "Label: no_relation\n",
      "FEP label: no_relation\n",
      "[0 1]\n",
      "[61 39]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 2)\n",
      "(100, 178)\n",
      "(100, 178)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "# Verifying that the labels are correct\n",
    "idx = random.choice(range(len(train_data)))\n",
    "ex = \" \".join(train_data[idx][\"token\"])\n",
    "label = train_data[idx][\"relation\"]\n",
    "print(\"Sentence: {}\\nLabel: {}\".format(ex, label))\n",
    "\n",
    "class_labels = { v : k for k, v in fep.get_class_labels().items()}\n",
    "fep_label = class_labels[np.argmax(Y[idx]).astype(int)]\n",
    "print(\"FEP label: {}\".format(fep_label))\n",
    "\n",
    "# Verifying class-imbalance issues\n",
    "labels = np.argmax(Y, axis = 1)\n",
    "keys, counts = np.unique(labels, return_counts = True)\n",
    "plt.bar(keys, counts)\n",
    "plt.title(\"Class distribution in resampled data\")\n",
    "plt.xticks(keys, [class_labels[k] for k in keys], rotation = -45)\n",
    "plt.show()\n",
    "\n",
    "# Verifying that all the shapes work out...\n",
    "print(Y.shape)\n",
    "print(X_full.shape)\n",
    "print(X_middle.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Evaluating the model and comparing to baselines"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
